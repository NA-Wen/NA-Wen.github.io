---
permalink: /
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

  My name is Yufan Dang (ÂÖö‰ΩôÂá°). I'm a undergrad at **Tsinghua university**(2021-2025) , double major in **MPS(math and physics science) & Software**. Now as a research intern at THUNLP, I'm learning around LLM & agent, and engaged in [ChatDev](https://github.com/OpenBMB/ChatDev) as a main contributor. 

  <!-- Holding a strong conviction that "Exploring the essence of intelligence will broaden the boundaries of cognition and contribute to a better world" I am currently strategizing to commence **a Ph.D. journey specializing in NLP/LLM/ML/DL**. My goal is to advance my academic pursuits, with the anticipated initiation of this endeavor **in the fall of 2025**.\\ -->
  
  I have a passion for sharing _tech blogs_ on my [blog site](https://cuddly-athlete-ff1.notion.site/NA-Wen-s-blog-6efd65e06b934c369ba0f0ad7901c4f8), where I discuss the courses I am currently enrolled in and share insights into cutting-edge papers and news.


  Aside from research and tons of math and physics, I love volleyball / gym workingout / tennis / hiking and I'm a violin enthusiast.

  
  Feel free to reach me : [dangyf2003@gmail.com](mailto:dangyf2003@gmail.com). 


**Research Interest:**
  <details>
  <summary>
  LLM agents ü§ñ </summary>
    I aim to constructing LLM-based autonomous agent for effctively and efficiently solving multi-step and complex tasks (previously mainly focus on software developing, now try to explore more) to fully leverage the ability of LLMs.
    I'm curious about the topic of LLM-based multi-agent: What is the definition of multi-agent? What will happen when more agents involved in one task or conversation or some real-world scenario? What is the lying difference between multi-agent and single agent, more is all you need? We need the strongest agent or more weak agents gathered to reach another stage of LLM agent? How can we leverage the potiential of multi-agent, for simulation, for task-solving, or just for fun?
    </details>
  <details>
  <summary>
  Information theory/Learning theory üé® </summary>
  The breakthroughs in language models became evident in 2022, overshadowing advancements in computer vision.
  These language models excel as sophisticated compressors of linguistic data, adeptly encapsulating and harnessing the latent intelligence embedded within language through their parameters.
    My ambition lies in unraveling the fundamental aspects of language intelligence, primarily through the perspectives of information theory and learning theory, which aims to provide a more holistic understanding of the current capabilities of LLMs.
    And I'm devoted to utilize the perspective of information theory to understand the current agent work. It is an interesting topic.
    </details>



## üç∫ News
- [2024.5.16] Our two papers have been accepted to **ACL 2024, main conference** ü•≥. **Thanks to my best mentor and all co-authors!**
- [2024.5.6]  Following our prior work on ECL, we're excited to announce the publication of our latest endeavor, **Iterative Experience Refinement of Software-Developing Agents**, available on [arXiv:2405.04219, 2024](https://arxiv.org/abs/2405.04219). 
- [2024.1.25]  Code and data around **Experiential Co-Learning of Software-Developing Agents** has released in [ECL](https://github.com/OpenBMB/ChatDev/blob/main/wiki.md#experiential-co-learning-guide). 
- [2023.12.29]  Our recent work **Experiential Co-Learning of Software-Developing Agents** has released on [arXiv:2307.07924, 2023](https://arxiv.org/abs/2307.07924). 

## üí° Publication
**[Experiential Co-Learning of Software-Developing Agents](https://arxiv.org/abs/2312.17025)**. ACL 2024 main conference
Chen Qian$^{‚Ä†}$, **Yufan Dang**$^{‚Ä†}$, Jiahao Li, Wei Liu, Weize Chen, Cheng Yang, Zhiyuan Liu, Maosong Sun.

**[Communicative Agents for Software Development](https://arxiv.org/abs/2307.07924)**. ACL 2024 main conference
Chen Qian, Xin Cong, Wei Liu, Cheng Yang, Weize Chen, Yusheng Su, **Yufan Dang** , Jiahao Li, Juyuan Xu, Dahai Li, Zhiyuan Liu, Maosong Sun.


**Iterative Experience Refinement of Software-Developing Agents**. In [arXiv:2405.04219, 2024](https://arxiv.org/abs/2405.04219). 
Chen Qian$^{‚Ä†}$, Jiahao Li$^{‚Ä†}$, **Yufan Dang**, Wei Liu, YiFei Wang, Zihao Xie, Weize Chen, Cheng Yang, Yingli Zhang, Zhiyuan Liu, Maosong Sun.

$^{‚Ä†}$:Equal Contribution

## üê£ Research Experience

**THUNLP Natural Language Processing Lab at Tsinghua University** \\
Research Intern, Jul 2023 ‚Äì Present

- Participating in the [ChatDev](https://github.com/OpenBMB/ChatDev) project: optimizing dialogue-related mechanisms of the AI, conducting multiple testing, improving the project's frontend, and carrying out daily operational maintenance

- Currently involved in agent-oriented co-evolution research, accumulating experience and facilitating the mutual evolution of capabilities 

**Development and Application of Driving Safety AI Detection System** \\
Student Research Training Program in Autonomous Department, Tsinghua University, Nov 2022 ‚Äì Jun 2023

- Focus on multimodal perception based on deep learning in self-driving
- Researched the state-of-the-art single terminal and multimodal perception network and got to know techniques about computer vision
- Used Pytorch to replicate advanced algorithms in communication-efficient collaborative perception and reproduced consistent experimental results


